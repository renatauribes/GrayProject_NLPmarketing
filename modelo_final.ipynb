{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ad031-9a96-4c54-8920-a1821893b392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import copy\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0dac6-e7bb-4029-8c26-ffec5e1a899f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_clean = pd.read_csv(\"../df_clean-2.csv\").drop(columns=\"index\")\n",
    "\n",
    "df_data = df_clean[df_clean.Target != \"UNKNOWN\"]\n",
    "df_pred = df_clean[df_clean.Target == \"UNKNOWN\"]\n",
    "df_data = df_data.reset_index().drop(columns=[\"index\"])\n",
    "df_pred = df_pred.reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "\n",
    "map = {\n",
    "\"Program\":        0,\n",
    "\"Display\":        1,\n",
    "\"BTB\":            2,\n",
    "\"Search\":         3,\n",
    "\"Holiday\":        4,\n",
    "\"BTS\":            5,\n",
    "\"Email\":          6,\n",
    "\"Digital\":        7,\n",
    "\"Trad_media\":     8\n",
    "}\n",
    "\n",
    "y_df = df_data[\"Target\"].map(map)\n",
    "X_df = pd.DataFrame({\"Name\": [ast.literal_eval(i) for i in df_data[\"Name\"].values.tolist()], \"Descr\": [ast.literal_eval(i) for i in df_data[\"Descr\"].values.tolist()]}) \n",
    "\n",
    "concat = []\n",
    "for j, i in zip(X_df [\"Name\"].values, X_df [\"Descr\"].values):\n",
    "  new = copy.deepcopy(j)\n",
    "  for k in i:\n",
    "    new.append(copy.deepcopy(k))\n",
    "  concat.append(new)\n",
    "X_df [\"Concat\"] = concat\n",
    "\n",
    "X = X_df[\"Concat\"]\n",
    "y = y_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ffe021-9b47-4856-ae58-daa233900318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self, embeding_vector_size = 100, skipg_window = 3, min_count = 2, use_sg = 1):\n",
    "        \n",
    "        # entry vectors\n",
    "        \n",
    "        self.X = \"nan\"\n",
    "        self.y = \"nan\"\n",
    "        \n",
    "        # last prediction\n",
    "        \n",
    "        self.y_pred = \"nan\"\n",
    "        \n",
    "        # expanded categories vectors \n",
    "        \n",
    "        self.X_sub = \"nan\"\n",
    "        self.y_sub = \"nan\"\n",
    "        \n",
    "        # last embeded sentences vector\n",
    "        \n",
    "        self.X_vect_avg = []\n",
    "        \n",
    "        # created subcategories visualization\n",
    "        \n",
    "        self.subcategories_df = \"nan\"\n",
    "        \n",
    "        # number of clusters to generate per class \"K\"\n",
    "        \n",
    "        self.n_clusters = \"nan\"\n",
    "        \n",
    "        # models \n",
    "        \n",
    "        self.w2v_model = \"nan\"\n",
    "        self.kmeanModel = \"nan\"\n",
    "        self.svc = \"nan\"\n",
    "        \n",
    "        # w2v hyperparameters\n",
    "        \n",
    "        self.embeding_vector_size = embeding_vector_size\n",
    "        self.skipg_window = skipg_window\n",
    "        self.min_count = min_count\n",
    "        self.use_sg = use_sg\n",
    "        \n",
    "    \n",
    "    def __clusterize(self, classes_df, labels):\n",
    "        new_classes_dic = {}\n",
    "        for i in classes_df:\n",
    "            class_labels = labels[i][self.n_clusters[i]]\n",
    "            new_class_labels = []\n",
    "            for j in class_labels:\n",
    "                new_class_labels.append(i + \" \" + str(j))\n",
    "            new_classes_dic[i] = pd.DataFrame({\"Target\": new_class_labels, \"sentence\": classes_df[i][\"sentence\"].values.tolist()})\n",
    "        new_classes_dic = pd.concat(new_classes_dic.values(), ignore_index=True)\n",
    "        \n",
    "        self.new_map = {np.unique(new_classes_dic[\"Target\"].values)[i]:i  for i in range(len(np.unique(new_classes_dic[\"Target\"].values)))}\n",
    "        self.y_sub = new_classes_dic[\"Target\"].map(self.new_map)\n",
    "        self.X_sub = new_classes_dic[\"sentence\"].values.tolist()\n",
    "        self.subcategories_df = pd.DataFrame({\"Target key\": self.y_sub,\"Target\": new_classes_dic[\"Target\"], \"sentence\": self.X_sub})\n",
    "        \n",
    "\n",
    "    \n",
    "    def fit(self, X, y, n_clusters):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_clusters = n_clusters\n",
    "        \n",
    "        # training w2v\n",
    "        \n",
    "        self.w2v_model = gensim.models.Word2Vec(sentences = self.X,\n",
    "                                   vector_size=self.embeding_vector_size,\n",
    "                                   window=self.skipg_window,\n",
    "                                   min_count=self.min_count,\n",
    "                                   sg=self.use_sg)\n",
    "        \n",
    "        # arranging sentences with embeded words\n",
    "        \n",
    "        words = set(self.w2v_model.wv.index_to_key )\n",
    "        X_vect = np.array([np.array([self.w2v_model.wv[i] for i in ls if i in words]) for ls in X])\n",
    "\n",
    "        # averaging words into sentence\n",
    "\n",
    "        \n",
    "        for v in X_vect:\n",
    "            if v.size:\n",
    "                self.X_vect_avg.append(v.mean(axis=0))\n",
    "            else:\n",
    "                self.X_vect_avg.append(np.zeros(vector_size, dtype=float))\n",
    "                \n",
    "        # dividing the different categories to prepare them for clustering\n",
    "                \n",
    "        df = pd.DataFrame({\"Target\": self.y, \"sentence\": self.X_vect_avg})\n",
    " \n",
    "        classes = {i: df[df.Target == map[i]] for i in map}\n",
    "        for i in classes:\n",
    "            classes[i] = classes[i].reset_index().drop(columns=[\"index\"])\n",
    "        \n",
    "        # clustering from k = 1 to k = 12 to match the given map\n",
    "        \n",
    "        labels = {}\n",
    "\n",
    "        for i in classes:\n",
    "            i_labels = {}\n",
    "            K = range(1,12)\n",
    "            for k in K:\n",
    "                self.kmeanModel = KMeans(n_clusters=k, algorithm=\"elkan\").fit(classes[i]['sentence'].values.tolist())\n",
    "                i_labels[k] = self.kmeanModel.labels_\n",
    "            labels[i] = i_labels\n",
    "            \n",
    "        # arranging and selecting clustering results\n",
    "        \n",
    "        self.__clusterize(classes, labels)\n",
    "        \n",
    "        # training SVC\n",
    "        \n",
    "        self.svc = SVC(kernel = \"linear\").fit(self.X_sub, self.y_sub)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # arranging sentences with embeded words\n",
    "        \n",
    "        words = set(self.w2v_model.wv.index_to_key)\n",
    "        X_vect = np.array([np.array([self.w2v_model.wv[i] for i in ls if i in words]) for ls in X])\n",
    "\n",
    "        # averaging words into sentence\n",
    "\n",
    "        self.X_vect_avg = []\n",
    "        \n",
    "        for v in X_vect:\n",
    "            if v.size:\n",
    "                self.X_vect_avg.append(v.mean(axis=0))\n",
    "            else:\n",
    "                self.X_vect_avg.append(np.zeros(self.embeding_vector_size, dtype=float))\n",
    "\n",
    "                \n",
    "        self.svc.prediction = self.svc.predict(self.X_vect_avg)\n",
    "        \n",
    "        return self.svc.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfc3ea-7b8e-4be2-bf09-b38d664a2775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "n_clusters = {\n",
    "\"Program\":        10,\n",
    "\"Display\":        5,\n",
    "\"BTB\":            3,\n",
    "\"Search\":         4,\n",
    "\"Holiday\":        5,\n",
    "\"BTS\":            5,\n",
    "\"Email\":          2,\n",
    "\"Digital\":        1,\n",
    "\"Trad_media\":     1\n",
    "}\n",
    "\n",
    "mod = model()\n",
    "mod.fit(X_train ,y_train, n_clusters)\n",
    "y_pred = mod.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ff31a-cbf4-4810-998a-47047060717f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_test(y_pred, original_map):\n",
    "        n_map = {}\n",
    "        for i in mod.new_map:\n",
    "            for j in original_map:\n",
    "                if(j == i[:len(j)]):\n",
    "                    n_map[mod.new_map[i]] = original_map[j]\n",
    "                    break\n",
    "        return pd.Series(y_pred).map(n_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facba35b-80ea-4373-9bc4-19df07a98923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, map_test(y_pred, map))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
